{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8it_9hgO6w2j"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y-z378P6zN1",
        "outputId": "bd9b6125-5456-4313-da2d-f1dd726c3547"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading brain-tumor-mri-dataset.zip to /content\n",
            " 93% 138M/149M [00:00<00:00, 198MB/s]\n",
            "100% 149M/149M [00:00<00:00, 197MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_path = '/content/brain-tumor-mri-dataset.zip'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/brain_tumor_dataset')"
      ],
      "metadata": {
        "id": "c3WL2vw264re"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from time import time\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard, LambdaCallback\n",
        "from keras.layers import Input, Dropout, Dense, GlobalAveragePooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.resnet import ResNet50\n"
      ],
      "metadata": {
        "id": "sjGrGAfS66IY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define labels and image size\n",
        "labels = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "image_size = 150\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, 0)\n",
        "    image = cv2.bilateralFilter(image, 2, 50, 50)\n",
        "    image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
        "    image = cv2.resize(image, (image_size, image_size))\n",
        "    return image\n",
        "\n",
        "# Load images and labels\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for label in labels:\n",
        "    trainPath = os.path.join('/content/brain_tumor_dataset/Training', label)\n",
        "    for file in tqdm(os.listdir(trainPath)):\n",
        "        image_path = os.path.join(trainPath, file)\n",
        "        x_train.append(preprocess_image(image_path))\n",
        "        y_train.append(labels.index(label))\n",
        "\n",
        "    testPath = os.path.join('/content/brain_tumor_dataset/Testing', label)\n",
        "    for file in tqdm(os.listdir(testPath)):\n",
        "        image_path = os.path.join(testPath, file)\n",
        "        x_test.append(preprocess_image(image_path))\n",
        "        y_test.append(labels.index(label))\n",
        "\n",
        "# Convert lists to NumPy arrays and normalize images\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Shuffle training data\n",
        "x_train, y_train = shuffle(x_train, y_train, random_state=42)\n",
        "\n",
        "# Perform one-hot encoding on labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxiL_DLs7G2T",
        "outputId": "6691e8c1-6c96-490e-8cb5-ac64a6341095"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1321/1321 [00:09<00:00, 141.95it/s]\n",
            "100%|██████████| 300/300 [00:01<00:00, 183.02it/s]\n",
            "100%|██████████| 1339/1339 [00:08<00:00, 164.23it/s]\n",
            "100%|██████████| 306/306 [00:01<00:00, 208.46it/s]\n",
            "100%|██████████| 1595/1595 [00:06<00:00, 231.88it/s]\n",
            "100%|██████████| 405/405 [00:01<00:00, 335.77it/s]\n",
            "100%|██████████| 1457/1457 [00:10<00:00, 135.20it/s]\n",
            "100%|██████████| 300/300 [00:01<00:00, 176.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"TensorFlow Probability version:\", tfp.__version__)\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "print(\"NumPy version:\", np.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrKRtfz87k5V",
        "outputId": "236228d9-b3c6-446e-eba4-946ccfa1f7ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "TensorFlow Probability version: 0.23.0\n",
            "Keras version: 2.15.0\n",
            "NumPy version: 1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet50**"
      ],
      "metadata": {
        "id": "6lY6n40C7tBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from time import time\n",
        "\n",
        "# Define ResNet50-based model\n",
        "def build_resnet_model(input_shape):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    predictions = layers.Dense(4, activation='sigmoid')(x)  # Adjust output units to 4\n",
        "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False  # Freeze pre-trained layers\n",
        "    return model\n",
        "\n",
        "# Instantiate the ResNet50-based model\n",
        "input_shape = (150, 150, 3)  # Assuming input shape is (150, 150, 3)\n",
        "resnet_model = build_resnet_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = optimizers.Adam(learning_rate=0.0001)  # Adjust learning rate if needed\n",
        "resnet_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start_time = time()\n",
        "early_stopping = EarlyStopping(patience=3, restore_best_weights=True)  # Add early stopping to prevent overfitting\n",
        "resnet_history = resnet_model.fit(x_train, y_train,\n",
        "                                  batch_size=32,\n",
        "                                  epochs=10,  # Increase epochs if needed\n",
        "                                  validation_data=(x_val, y_val),\n",
        "                                  callbacks=[early_stopping])\n",
        "end_time = time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = resnet_model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {resnet_history.history[\"accuracy\"][-1]}')  # Print final training accuracy\n",
        "print(f'Validation Acc: {resnet_history.history[\"val_accuracy\"][-1]}')  # Print final validation accuracy\n",
        "print(f'Test Acc: {test_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-dJ18wu7qlP",
        "outputId": "10c38a3d-644d-4c44-a2fa-73e995c534ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 546s 4s/step - loss: 0.5336 - accuracy: 0.4193 - val_loss: 0.4993 - val_accuracy: 0.5311\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 533s 4s/step - loss: 0.4792 - accuracy: 0.5572 - val_loss: 0.4728 - val_accuracy: 0.6107\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 534s 4s/step - loss: 0.4552 - accuracy: 0.5881 - val_loss: 0.4521 - val_accuracy: 0.5862\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 482s 3s/step - loss: 0.4385 - accuracy: 0.6161 - val_loss: 0.4387 - val_accuracy: 0.6133\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 528s 4s/step - loss: 0.4247 - accuracy: 0.6316 - val_loss: 0.4251 - val_accuracy: 0.6317\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 527s 4s/step - loss: 0.4141 - accuracy: 0.6380 - val_loss: 0.4131 - val_accuracy: 0.6588\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 484s 3s/step - loss: 0.4023 - accuracy: 0.6599 - val_loss: 0.4032 - val_accuracy: 0.6640\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 527s 4s/step - loss: 0.3925 - accuracy: 0.6699 - val_loss: 0.3951 - val_accuracy: 0.6710\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 527s 4s/step - loss: 0.3846 - accuracy: 0.6715 - val_loss: 0.3874 - val_accuracy: 0.6737\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 528s 4s/step - loss: 0.3771 - accuracy: 0.6800 - val_loss: 0.3814 - val_accuracy: 0.6842\n",
            "41/41 [==============================] - 111s 3s/step - loss: 0.4272 - accuracy: 0.6064\n",
            "Test Loss: 0.427184134721756\n",
            "Test Accuracy: 0.6064073443412781\n",
            "Time taken: 5251.655034542084 seconds\n",
            "Training Acc: 0.6800175309181213\n",
            "Validation Acc: 0.6841644644737244\n",
            "Test Acc: 0.6064073443412781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jd-t4VoV7w0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}