{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "pFu-9Lb0z0xl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "GnKNrg1FlN_d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mohamedhanyyy/chest-ctscan-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MRuuLtgk6w5",
        "outputId": "c366b155-b07f-45df-e157-530996f45d85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading chest-ctscan-images.zip to /content\n",
            " 95% 113M/119M [00:02<00:00, 59.7MB/s]\n",
            "100% 119M/119M [00:02<00:00, 60.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_file_path = '/content/chest-ctscan-images.zip'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "QS9eWGRLlKZ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121, VGG16\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate, Dense, GlobalAveragePooling2D, BatchNormalization, Flatten\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from time import time\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard, LambdaCallback\n",
        "from keras.layers import Input, Dropout, Dense, GlobalAveragePooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.resnet import ResNet50\n"
      ],
      "metadata": {
        "id": "P8K2TCckray6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls /content/Data/test\n",
        "%ls /content/Data/train\n",
        "%ls /content/Data/valid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFBpb0af0EMS",
        "outputId": "d0a82648-82c4-4b7b-af01-dbbf94ee2112"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34madenocarcinoma\u001b[0m/  \u001b[01;34mlarge.cell.carcinoma\u001b[0m/  \u001b[01;34mnormal\u001b[0m/  \u001b[01;34msquamous.cell.carcinoma\u001b[0m/\n",
            "\u001b[0m\u001b[01;34madenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\u001b[0m/     \u001b[01;34mnormal\u001b[0m/\n",
            "\u001b[01;34mlarge.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\u001b[0m/  \u001b[01;34msquamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\u001b[0m/\n",
            "\u001b[0m\u001b[01;34madenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\u001b[0m/     \u001b[01;34mnormal\u001b[0m/\n",
            "\u001b[01;34mlarge.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\u001b[0m/  \u001b[01;34msquamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Define image size\n",
        "image_size = 150\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, 0)\n",
        "    image = cv2.bilateralFilter(image, 2, 50, 50)\n",
        "    image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
        "    image = cv2.resize(image, (image_size, image_size))\n",
        "    return image\n",
        "\n",
        "# Define data directories\n",
        "data_dirs = {\n",
        "    'train': '/content/Data/train',\n",
        "    'test': '/content/Data/test',\n",
        "    'valid': '/content/Data/valid'\n",
        "}\n",
        "\n",
        "# Initialize lists to store data\n",
        "data = {split: {'images': [], 'labels': []} for split in data_dirs}\n",
        "\n",
        "# Iterate over data directories\n",
        "for split, directory in data_dirs.items():\n",
        "    for label in os.listdir(directory):\n",
        "        label_dir = os.path.join(directory, label)\n",
        "        for file in tqdm(os.listdir(label_dir), desc=f'Processing {split}/{label}'):\n",
        "            image_path = os.path.join(label_dir, file)\n",
        "            data[split]['images'].append(preprocess_image(image_path))\n",
        "            data[split]['labels'].append(label)\n",
        "\n",
        "# Convert lists to NumPy arrays and normalize images\n",
        "for split in data:\n",
        "    data[split]['images'] = np.array(data[split]['images']) / 255.0\n",
        "    data[split]['labels'] = np.array(data[split]['labels'])\n",
        "\n",
        "# Extract unique labels present in the data\n",
        "unique_labels = np.unique(np.concatenate([data[split]['labels'] for split in data]))\n",
        "\n",
        "# Convert labels to one-hot encoding using dynamically extracted labels\n",
        "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
        "for split in data:\n",
        "    data[split]['labels'] = tf.keras.utils.to_categorical([label_to_index[label] for label in data[split]['labels']], num_classes=len(unique_labels))\n",
        "\n",
        "\n",
        "# Shuffle training data\n",
        "data['train']['images'], data['train']['labels'] = shuffle(data['train']['images'], data['train']['labels'], random_state=42)\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "train_val_split = 0.2\n",
        "val_test_split = 0.5\n",
        "x_train, x_val_test, y_train, y_val_test = train_test_split(data['train']['images'], data['train']['labels'], test_size=train_val_split, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=val_test_split, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAjkf3QCz94g",
        "outputId": "2bbb58e1-ddb2-4be3-c645-a6d4c51c8065"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa: 100%|██████████| 155/155 [00:01<00:00, 115.98it/s]\n",
            "Processing train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib: 100%|██████████| 195/195 [00:02<00:00, 94.64it/s]\n",
            "Processing train/normal: 100%|██████████| 148/148 [00:03<00:00, 42.46it/s]\n",
            "Processing train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa: 100%|██████████| 115/115 [00:00<00:00, 141.17it/s]\n",
            "Processing test/squamous.cell.carcinoma: 100%|██████████| 90/90 [00:01<00:00, 85.06it/s]\n",
            "Processing test/adenocarcinoma: 100%|██████████| 120/120 [00:01<00:00, 88.27it/s] \n",
            "Processing test/normal: 100%|██████████| 54/54 [00:01<00:00, 38.24it/s]\n",
            "Processing test/large.cell.carcinoma: 100%|██████████| 51/51 [00:00<00:00, 113.36it/s]\n",
            "Processing valid/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa: 100%|██████████| 15/15 [00:00<00:00, 140.27it/s]\n",
            "Processing valid/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib: 100%|██████████| 23/23 [00:00<00:00, 115.63it/s]\n",
            "Processing valid/normal: 100%|██████████| 13/13 [00:00<00:00, 39.81it/s]\n",
            "Processing valid/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa: 100%|██████████| 21/21 [00:00<00:00, 184.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n"
      ],
      "metadata": {
        "id": "_vkbjgeI27_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vgg16**"
      ],
      "metadata": {
        "id": "fM5eIu645Mz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "# Add custom output layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on training data\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16SSwX994mDe",
        "outputId": "52058c4e-c161-4644-8fb7-437d80a926d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 30s 868ms/step - loss: 2.2023 - accuracy: 0.2265 - val_loss: 1.7030 - val_accuracy: 0.2951\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.4107 - accuracy: 0.2898 - val_loss: 1.4114 - val_accuracy: 0.2295\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 3s 196ms/step - loss: 1.3035 - accuracy: 0.3959 - val_loss: 1.2850 - val_accuracy: 0.4098\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 3s 197ms/step - loss: 1.0961 - accuracy: 0.4694 - val_loss: 1.0431 - val_accuracy: 0.4426\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9949 - accuracy: 0.5122 - val_loss: 1.2600 - val_accuracy: 0.3934\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 3s 200ms/step - loss: 1.0806 - accuracy: 0.4755 - val_loss: 1.0730 - val_accuracy: 0.5410\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 3s 199ms/step - loss: 0.9616 - accuracy: 0.5612 - val_loss: 0.9382 - val_accuracy: 0.5082\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.9272 - accuracy: 0.5898 - val_loss: 1.0880 - val_accuracy: 0.4262\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 3s 202ms/step - loss: 0.9694 - accuracy: 0.5694 - val_loss: 0.8800 - val_accuracy: 0.5082\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 3s 201ms/step - loss: 0.8822 - accuracy: 0.5980 - val_loss: 0.8460 - val_accuracy: 0.5246\n",
            "2/2 [==============================] - 4s 3s/step - loss: 0.9313 - accuracy: 0.6129\n",
            "Test Loss: 0.9313302636146545\n",
            "Test Accuracy: 0.6129032373428345\n",
            "Time taken: 59.27309775352478 seconds\n",
            "Training Acc: 0.4687755048274994\n",
            "Validation Acc: 0.42786884903907774\n",
            "Test Acc: 0.6129032373428345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**InceptionV3**"
      ],
      "metadata": {
        "id": "-d69kuNY5RyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load pre-trained InceptionV3 model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "\n",
        "# Add custom output layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on training data\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k406uX_s5VQE",
        "outputId": "fa3bbee0-5bd6-4282-f32d-4a8f6389d07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 49s 653ms/step - loss: 1.2042 - accuracy: 0.5653 - val_loss: 3.7733 - val_accuracy: 0.3443\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 2s 146ms/step - loss: 0.3508 - accuracy: 0.9184 - val_loss: 4.1972 - val_accuracy: 0.2787\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.1106 - accuracy: 0.9857 - val_loss: 2.8532 - val_accuracy: 0.3279\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 2s 110ms/step - loss: 0.0433 - accuracy: 0.9898 - val_loss: 1.9943 - val_accuracy: 0.4426\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0350 - accuracy: 0.9918 - val_loss: 1.5689 - val_accuracy: 0.4918\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 2s 112ms/step - loss: 0.0327 - accuracy: 0.9959 - val_loss: 1.2874 - val_accuracy: 0.6066\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 2s 111ms/step - loss: 0.0208 - accuracy: 0.9959 - val_loss: 1.0666 - val_accuracy: 0.6393\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.7872 - val_accuracy: 0.7377\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 2s 113ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.6621 - val_accuracy: 0.7705\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.5295 - val_accuracy: 0.8033\n",
            "2/2 [==============================] - 2s 2s/step - loss: 0.5638 - accuracy: 0.8065\n",
            "Test Loss: 0.5638082027435303\n",
            "Test Accuracy: 0.8064516186714172\n",
            "Time taken: 66.80860137939453 seconds\n",
            "Training Acc: 0.9428571462631226\n",
            "Validation Acc: 0.54426229596138\n",
            "Test Acc: 0.8064516186714172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vgg19**"
      ],
      "metadata": {
        "id": "Vg7Y6ZZv5edA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "# Load pre-trained VGG19 model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "# Add custom output layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on training data\n",
        "start_time = time.time()\n",
        "history = model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_val, y_val))\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq49b32K5j9Z",
        "outputId": "774cf1d5-b9fd-4210-f066-5dbd9407f0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 10s 293ms/step - loss: 1.3351 - accuracy: 0.4408 - val_loss: 1.2242 - val_accuracy: 0.3443\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 4s 266ms/step - loss: 1.0233 - accuracy: 0.5184 - val_loss: 0.9702 - val_accuracy: 0.5738\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 4s 268ms/step - loss: 0.8208 - accuracy: 0.6306 - val_loss: 0.7541 - val_accuracy: 0.6393\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 4s 270ms/step - loss: 0.6049 - accuracy: 0.7408 - val_loss: 0.6525 - val_accuracy: 0.6721\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 5s 284ms/step - loss: 0.5059 - accuracy: 0.7939 - val_loss: 0.4657 - val_accuracy: 0.7541\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 4s 272ms/step - loss: 0.3044 - accuracy: 0.8816 - val_loss: 0.5353 - val_accuracy: 0.7705\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 4s 269ms/step - loss: 0.3280 - accuracy: 0.8796 - val_loss: 0.2745 - val_accuracy: 0.8852\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 4s 277ms/step - loss: 0.1478 - accuracy: 0.9571 - val_loss: 0.3957 - val_accuracy: 0.8525\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 4s 264ms/step - loss: 0.2015 - accuracy: 0.9245 - val_loss: 0.5081 - val_accuracy: 0.7869\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 4s 272ms/step - loss: 0.2373 - accuracy: 0.9000 - val_loss: 0.4354 - val_accuracy: 0.8361\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.8809 - accuracy: 0.8065\n",
            "Test Loss: 0.8809130191802979\n",
            "Test Accuracy: 0.8064516186714172\n",
            "Time taken: 85.37473702430725 seconds\n",
            "Training Acc: 0.7667346864938736\n",
            "Validation Acc: 0.71147540807724\n",
            "Test Acc: 0.8064516186714172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vemK_rDF6D-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XRPisDX-Z3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DUquFVj6-ZzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**apply noise**"
      ],
      "metadata": {
        "id": "GHFEYEe4-ajE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Define image size\n",
        "image_size = 150\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, 0)\n",
        "    image = cv2.bilateralFilter(image, 2, 50, 50)\n",
        "    image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
        "    image = cv2.resize(image, (image_size, image_size))\n",
        "    return image\n",
        "\n",
        "# Define data directories\n",
        "data_dirs = {\n",
        "    'train': '/content/Data/train',\n",
        "    'test': '/content/Data/test',\n",
        "    'valid': '/content/Data/valid'\n",
        "}\n",
        "\n",
        "# Initialize lists to store data\n",
        "data = {split: {'images': [], 'labels': []} for split in data_dirs}\n",
        "\n",
        "# Iterate over data directories\n",
        "for split, directory in data_dirs.items():\n",
        "    for label in os.listdir(directory):\n",
        "        label_dir = os.path.join(directory, label)\n",
        "        for file in tqdm(os.listdir(label_dir), desc=f'Processing {split}/{label}'):\n",
        "            image_path = os.path.join(label_dir, file)\n",
        "            data[split]['images'].append(preprocess_image(image_path))\n",
        "            data[split]['labels'].append(label)\n",
        "\n",
        "# Convert lists to NumPy arrays and normalize images\n",
        "for split in data:\n",
        "    data[split]['images'] = np.array(data[split]['images']) / 255.0\n",
        "    data[split]['labels'] = np.array(data[split]['labels'])\n",
        "\n",
        "# Extract unique labels present in the data\n",
        "unique_labels = np.unique(np.concatenate([data[split]['labels'] for split in data]))\n",
        "\n",
        "# Convert labels to one-hot encoding using dynamically extracted labels\n",
        "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
        "for split in data:\n",
        "    data[split]['labels'] = tf.keras.utils.to_categorical([label_to_index[label] for label in data[split]['labels']], num_classes=len(unique_labels))\n",
        "\n",
        "# Shuffle training data\n",
        "data['train']['images'], data['train']['labels'] = shuffle(data['train']['images'], data['train']['labels'], random_state=42)\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "train_val_split = 0.2\n",
        "val_test_split = 0.5\n",
        "x_train, x_val_test, y_train, y_val_test = train_test_split(data['train']['images'], data['train']['labels'], test_size=train_val_split, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=val_test_split, random_state=42)\n",
        "\n",
        "# Apply data augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG-0ziwm-cn2",
        "outputId": "31c79a63-062f-4717-d7c4-4e088538e2ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train/normal: 100%|██████████| 148/148 [00:01<00:00, 80.85it/s]\n",
            "Processing train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa: 100%|██████████| 155/155 [00:00<00:00, 168.06it/s]\n",
            "Processing train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa: 100%|██████████| 115/115 [00:00<00:00, 173.05it/s]\n",
            "Processing train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib: 100%|██████████| 195/195 [00:01<00:00, 169.33it/s]\n",
            "Processing test/normal: 100%|██████████| 54/54 [00:00<00:00, 68.19it/s]\n",
            "Processing test/large.cell.carcinoma: 100%|██████████| 51/51 [00:00<00:00, 147.95it/s]\n",
            "Processing test/squamous.cell.carcinoma: 100%|██████████| 90/90 [00:00<00:00, 135.50it/s]\n",
            "Processing test/adenocarcinoma: 100%|██████████| 120/120 [00:00<00:00, 130.51it/s]\n",
            "Processing valid/normal: 100%|██████████| 13/13 [00:00<00:00, 57.55it/s]\n",
            "Processing valid/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]\n",
            "Processing valid/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa: 100%|██████████| 21/21 [00:00<00:00, 193.70it/s]\n",
            "Processing valid/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib: 100%|██████████| 23/23 [00:00<00:00, 187.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vgg16**"
      ],
      "metadata": {
        "id": "scZ5kccM-kp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "# Add custom output layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on training data\n",
        "start_time = time.time()\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=len(x_train) // batch_size, epochs=epochs, validation_data=(x_val, y_val))\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6heGwGDH-c_2",
        "outputId": "bf613a74-a389-4d10-cce2-a605d3e19a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 8s 288ms/step - loss: 4.1279 - accuracy: 0.2314 - val_loss: 1.5649 - val_accuracy: 0.2951\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 4s 233ms/step - loss: 1.4518 - accuracy: 0.2817 - val_loss: 1.4457 - val_accuracy: 0.2951\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 5s 316ms/step - loss: 1.3442 - accuracy: 0.3166 - val_loss: 1.2323 - val_accuracy: 0.4590\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 4s 258ms/step - loss: 1.2064 - accuracy: 0.3886 - val_loss: 1.2940 - val_accuracy: 0.4918\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 4s 262ms/step - loss: 1.1136 - accuracy: 0.4667 - val_loss: 1.0758 - val_accuracy: 0.4754\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 4s 259ms/step - loss: 0.9691 - accuracy: 0.5459 - val_loss: 1.0467 - val_accuracy: 0.5082\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 4s 232ms/step - loss: 0.9760 - accuracy: 0.5218 - val_loss: 0.9069 - val_accuracy: 0.5902\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 4s 233ms/step - loss: 1.0282 - accuracy: 0.5415 - val_loss: 1.1534 - val_accuracy: 0.4590\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 4s 283ms/step - loss: 0.9181 - accuracy: 0.5873 - val_loss: 0.9111 - val_accuracy: 0.5738\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 4s 235ms/step - loss: 0.9731 - accuracy: 0.5437 - val_loss: 0.9349 - val_accuracy: 0.4590\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.9659 - accuracy: 0.5161\n",
            "Test Loss: 0.9659043550491333\n",
            "Test Accuracy: 0.5161290168762207\n",
            "Time taken: 47.386714220047 seconds\n",
            "Training Acc: 0.4800000011920929\n",
            "Validation Acc: 0.4819672018289566\n",
            "Test Acc: 0.5161290168762207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**vgg19**"
      ],
      "metadata": {
        "id": "YjOfYlM1AxmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "# Load pre-trained VGG19 model\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "# Add custom output layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on training data\n",
        "start_time = time.time()\n",
        "history =model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=len(x_train) // batch_size, epochs=epochs, validation_data=(x_val, y_val))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLKePs9M_fz_",
        "outputId": "d3475835-2d0c-48c7-c450-996eeb266cdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 10s 338ms/step - loss: 1.3775 - accuracy: 0.3690 - val_loss: 0.9667 - val_accuracy: 0.4754\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 5s 288ms/step - loss: 1.0694 - accuracy: 0.5000 - val_loss: 0.9101 - val_accuracy: 0.5246\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 5s 301ms/step - loss: 0.9994 - accuracy: 0.5131 - val_loss: 0.8544 - val_accuracy: 0.5902\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 5s 297ms/step - loss: 0.9448 - accuracy: 0.5393 - val_loss: 0.9683 - val_accuracy: 0.5082\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 5s 297ms/step - loss: 0.9227 - accuracy: 0.5677 - val_loss: 0.8547 - val_accuracy: 0.5574\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 4s 265ms/step - loss: 0.8658 - accuracy: 0.6048 - val_loss: 0.8846 - val_accuracy: 0.5738\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 5s 311ms/step - loss: 0.8799 - accuracy: 0.5830 - val_loss: 0.8439 - val_accuracy: 0.5574\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 6s 347ms/step - loss: 0.8556 - accuracy: 0.5895 - val_loss: 1.1282 - val_accuracy: 0.5082\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 4s 265ms/step - loss: 0.8302 - accuracy: 0.5873 - val_loss: 0.7848 - val_accuracy: 0.5902\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 6s 393ms/step - loss: 0.7914 - accuracy: 0.5961 - val_loss: 0.9723 - val_accuracy: 0.5574\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 1.1827 - accuracy: 0.5968\n",
            "Test Loss: 1.1826791763305664\n",
            "Test Accuracy: 0.5967742204666138\n",
            "Time taken: 58.038464307785034 seconds\n",
            "Training Acc: 0.5449781745672226\n",
            "Validation Acc: 0.5442622870206832\n",
            "Test Acc: 0.5967742204666138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4OsVLkUA946"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1YwRfFeBFHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**InceptionV3**"
      ],
      "metadata": {
        "id": "LFSI8yRjBErh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load pre-trained InceptionV3 model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "\n",
        "\n",
        "# Add custom output layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(unique_labels), activation='softmax')(x)\n",
        "\n",
        "# Model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model on training data\n",
        "start_time = time.time()\n",
        "history =model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), steps_per_epoch=len(x_train) // batch_size, epochs=epochs, validation_data=(x_val, y_val))\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_TSZ8BOBGGc",
        "outputId": "8bbfd36e-a246-43cc-9ad4-d01b41a938a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 33s 278ms/step - loss: 1.5595 - accuracy: 0.4345 - val_loss: 4.8767 - val_accuracy: 0.3279\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 3s 219ms/step - loss: 1.0361 - accuracy: 0.5852 - val_loss: 3.9309 - val_accuracy: 0.3443\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 3s 193ms/step - loss: 0.7605 - accuracy: 0.6979 - val_loss: 3.5044 - val_accuracy: 0.3279\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.6890 - accuracy: 0.6834 - val_loss: 2.7728 - val_accuracy: 0.4262\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.5620 - accuracy: 0.7795 - val_loss: 2.4372 - val_accuracy: 0.4426\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 3s 188ms/step - loss: 0.5943 - accuracy: 0.7380 - val_loss: 1.8669 - val_accuracy: 0.5410\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 3s 189ms/step - loss: 0.5174 - accuracy: 0.7948 - val_loss: 1.2144 - val_accuracy: 0.6066\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 0.4039 - accuracy: 0.8493 - val_loss: 1.2589 - val_accuracy: 0.5902\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 3s 203ms/step - loss: 0.3970 - accuracy: 0.8313 - val_loss: 1.0509 - val_accuracy: 0.6230\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 4s 243ms/step - loss: 0.3283 - accuracy: 0.8734 - val_loss: 0.8063 - val_accuracy: 0.7213\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 1.1570 - accuracy: 0.7419\n",
            "Test Loss: 1.156996250152588\n",
            "Test Accuracy: 0.7419354915618896\n",
            "Time taken: 72.01577949523926 seconds\n",
            "Training Acc: 0.7267157942056656\n",
            "Validation Acc: 0.49508196413516997\n",
            "Test Acc: 0.7419354915618896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Define image size\n",
        "image_size = 150\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, 0)\n",
        "    image = cv2.bilateralFilter(image, 2, 50, 50)\n",
        "    image = cv2.applyColorMap(image, cv2.COLORMAP_BONE)\n",
        "    image = cv2.resize(image, (image_size, image_size))\n",
        "    return image\n",
        "\n",
        "# Define data directories\n",
        "data_dirs = {\n",
        "    'train': '/content/Data/train',\n",
        "    'test': '/content/Data/test',\n",
        "    'valid': '/content/Data/valid'\n",
        "}\n",
        "\n",
        "# Initialize lists to store data\n",
        "data = {split: {'images': [], 'labels': []} for split in data_dirs}\n",
        "\n",
        "# Iterate over data directories\n",
        "for split, directory in data_dirs.items():\n",
        "    for label in os.listdir(directory):\n",
        "        label_dir = os.path.join(directory, label)\n",
        "        for file in tqdm(os.listdir(label_dir), desc=f'Processing {split}/{label}'):\n",
        "            image_path = os.path.join(label_dir, file)\n",
        "            data[split]['images'].append(preprocess_image(image_path))\n",
        "            data[split]['labels'].append(label)\n",
        "\n",
        "# Convert lists to NumPy arrays and normalize images\n",
        "for split in data:\n",
        "    data[split]['images'] = np.array(data[split]['images']) / 255.0\n",
        "    data[split]['labels'] = np.array(data[split]['labels'])\n",
        "\n",
        "# Extract unique labels present in the data\n",
        "unique_labels = np.unique(np.concatenate([data[split]['labels'] for split in data]))\n",
        "\n",
        "# Convert labels to one-hot encoding using dynamically extracted labels\n",
        "label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
        "for split in data:\n",
        "    data[split]['labels'] = np.array([label_to_index[label] for label in data[split]['labels']])\n",
        "\n",
        "# Shuffle training data\n",
        "data['train']['images'], data['train']['labels'] = shuffle(data['train']['images'], data['train']['labels'], random_state=42)\n",
        "\n",
        "# Split dataset into training, validation, and test sets\n",
        "train_val_split = 0.2\n",
        "val_test_split = 0.5\n",
        "x_train, x_val_test, y_train, y_val_test = train_test_split(data['train']['images'], data['train']['labels'], test_size=train_val_split, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_val_test, y_val_test, test_size=val_test_split, random_state=42)\n",
        "\n",
        "# Apply data augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Determine the number of output units based on the number of unique labels\n",
        "num_classes = len(unique_labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jRrXQnOpwxz",
        "outputId": "539da078-fe1f-4f34-c1fd-b650ab0f6419"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing train/normal: 100%|██████████| 148/148 [00:02<00:00, 68.44it/s]\n",
            "Processing train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa: 100%|██████████| 155/155 [00:01<00:00, 139.82it/s]\n",
            "Processing train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa: 100%|██████████| 115/115 [00:00<00:00, 141.19it/s]\n",
            "Processing train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib: 100%|██████████| 195/195 [00:01<00:00, 141.85it/s]\n",
            "Processing test/normal: 100%|██████████| 54/54 [00:00<00:00, 58.28it/s]\n",
            "Processing test/large.cell.carcinoma: 100%|██████████| 51/51 [00:00<00:00, 89.47it/s]\n",
            "Processing test/squamous.cell.carcinoma: 100%|██████████| 90/90 [00:01<00:00, 85.14it/s]\n",
            "Processing test/adenocarcinoma: 100%|██████████| 120/120 [00:01<00:00, 93.16it/s] \n",
            "Processing valid/normal: 100%|██████████| 13/13 [00:00<00:00, 52.47it/s]\n",
            "Processing valid/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa: 100%|██████████| 15/15 [00:00<00:00, 155.04it/s]\n",
            "Processing valid/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa: 100%|██████████| 21/21 [00:00<00:00, 155.77it/s]\n",
            "Processing valid/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib: 100%|██████████| 23/23 [00:00<00:00, 155.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Number of classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xoAmGkTHptJ",
        "outputId": "795ce0e7-cc6b-433f-a279-bbe1b41d4cf5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ",\n",
        "\n",
        " ,=1SDDDDDDDDDD"
      ],
      "metadata": {
        "id": "tkOL0o4EHXEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AifZ1M1XKXRN",
        "outputId": "4c785263-a596-4162-d527-307ea7b2bf57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import kerastuner as kt\n",
        "import numpy as np\n",
        "from time import time\n",
        "\n",
        "# Define Bayesian CNN model using Variational Inference\n",
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Convolutional layers\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Flatten layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense layers with variational dropout\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=3, step=1)):\n",
        "        model.add(layers.Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
        "                               activation='relu'))\n",
        "        model.add(layers.Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(num_classes))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4])),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define a tuner\n",
        "tuner = kt.Hyperband(build_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='keras_tuner_dir',\n",
        "                     project_name='bayesian_cnn')\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(x_train, y_train,\n",
        "             epochs=10,\n",
        "             validation_data=(x_val, y_val))\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Fit the best model\n",
        "start_time = time()\n",
        "history = best_model.fit(x_train, y_train,\n",
        "                         epochs=10,\n",
        "                         validation_data=(x_val, y_val))\n",
        "end_time = time()\n",
        "\n",
        "# Evaluate the best model on test data\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print metrics\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Print process time and metrics\n",
        "print(f'Time taken: {end_time - start_time} seconds')\n",
        "print(f'Training Acc: {np.mean(history.history[\"accuracy\"])}')\n",
        "print(f'Validation Acc: {np.mean(history.history[\"val_accuracy\"])}')\n",
        "print(f'Test Acc: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "YeARbmD0_ATY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89353a43-9ecd-4b0a-8407-0a9389bea403"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 12s]\n",
            "val_accuracy: 0.4754098355770111\n",
            "\n",
            "Best val_accuracy So Far: 0.9180327653884888\n",
            "Total elapsed time: 00h 08m 18s\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 4s 83ms/step - loss: 0.1676 - accuracy: 0.9510 - val_loss: 0.3365 - val_accuracy: 0.8525\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.1276 - accuracy: 0.9551 - val_loss: 0.2463 - val_accuracy: 0.9180\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.0754 - accuracy: 0.9837 - val_loss: 0.3465 - val_accuracy: 0.9016\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.0415 - accuracy: 0.9857 - val_loss: 0.2521 - val_accuracy: 0.9180\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.0730 - accuracy: 0.9980 - val_loss: 0.3100 - val_accuracy: 0.8689\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 1s 58ms/step - loss: 0.0325 - accuracy: 0.9939 - val_loss: 0.2229 - val_accuracy: 0.9344\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.0306 - accuracy: 0.9980 - val_loss: 0.2543 - val_accuracy: 0.9180\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0156 - accuracy: 0.9959 - val_loss: 0.2440 - val_accuracy: 0.9016\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.0294 - accuracy: 0.9980 - val_loss: 0.2485 - val_accuracy: 0.9344\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0175 - accuracy: 0.9939 - val_loss: 0.5280 - val_accuracy: 0.8689\n",
            "2/2 [==============================] - 1s 987ms/step - loss: 0.8946 - accuracy: 0.8871\n",
            "Test Loss: 0.894563615322113\n",
            "Test Accuracy: 0.8870967626571655\n",
            "Time taken: 23.84615135192871 seconds\n",
            "Training Acc: 0.9853061199188232\n",
            "Validation Acc: 0.90163933634758\n",
            "Test Acc: 0.8870967626571655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_v2YSiRVItvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}